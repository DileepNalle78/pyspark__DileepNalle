{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyCPEYr2vAJvdQnsFs9A1j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DileepNalle78/pyspark__DileepNalle/blob/main/sales.csv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LINUX BASIC\n",
        "\n"
      ],
      "metadata": {
        "id": "6l06o0P0q_sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat /etc/os-release"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tuaBrsBpsJu",
        "outputId": "7dadcd60-fcf5-4aeb-b4e7-6a0ca973685b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PRETTY_NAME=\"Ubuntu 22.04.4 LTS\"\n",
            "NAME=\"Ubuntu\"\n",
            "VERSION_ID=\"22.04\"\n",
            "VERSION=\"22.04.4 LTS (Jammy Jellyfish)\"\n",
            "VERSION_CODENAME=jammy\n",
            "ID=ubuntu\n",
            "ID_LIKE=debian\n",
            "HOME_URL=\"https://www.ubuntu.com/\"\n",
            "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
            "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
            "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
            "UBUNTU_CODENAME=jammy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uname -a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgDvLNuXqFAf",
        "outputId": "04a08de4-55d2-4854-db0b-d51314718e2b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linux 6d3647f0c437 6.1.123+ #1 SMP PREEMPT_DYNAMIC Sun Mar 30 16:01:29 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whoami"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frGDZ2CAqP11",
        "outputId": "939fbe66-dba8-45fe-925e-5ba4d99b3ff0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3wwzlOUqgLT",
        "outputId": "ce870f83-16e8-412e-e007-2fd243ec2e40"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PySpark Basics"
      ],
      "metadata": {
        "id": "Pdks7cnOtJ0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pyspark\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTHmBGEZqjHB",
        "outputId": "4add7874-0fd3-47ea-c7f9-b08f0897760e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO2k8unOuFqE",
        "outputId": "b37bf375-cb4d-4d53-b6fa-21e9b3cda924"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: pyspark\n",
            "Version: 3.5.1\n",
            "Summary: Apache Spark Python API\n",
            "Home-page: https://github.com/apache/spark/tree/master/python\n",
            "Author: Spark Developers\n",
            "Author-email: dev@spark.apache.org\n",
            "License: http://www.apache.org/licenses/LICENSE-2.0\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: py4j\n",
            "Required-by: dataproc-spark-connect\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "KcvOfQ2yuJw9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"Basics\").getOrCreate()"
      ],
      "metadata": {
        "id": "kU96jmpouaog"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create DataFrame\n",
        "data = [(\"HEllo\",\"world\")]\n",
        "columns = [\"world1\",\"world2\"]\n",
        "\n",
        "df = spark.createDataFrame"
      ],
      "metadata": {
        "id": "kRQKHS3OvGMD"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark"
      ],
      "metadata": {
        "id": "_C91JB-JwEbp"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "data frame"
      ],
      "metadata": {
        "id": "TQ8A_cqzw0ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\"Name\",\"Department\",\"Salary\"]\n",
        "data = [\n",
        "    (\"John\", \"Sales\", 3000),\n",
        "    (\"Jane\", \"Finance\", 4000),\n",
        "    (\"Mike\", \"Sales\", 3500),\n",
        "    (\"Alice\", \"Finance\", 3800),\n",
        "    (\"Bob\", \"IT\", 4500)\n",
        "]\n",
        "\n",
        "df=spark.createDataFrame(data, columns)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDVItNmMwG7p",
        "outputId": "8965c74c-a356-48c1-b3a9-53bb8931128c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+------+\n",
            "| Name|Department|Salary|\n",
            "+-----+----------+------+\n",
            "| John|     Sales|  3000|\n",
            "| Jane|   Finance|  4000|\n",
            "| Mike|     Sales|  3500|\n",
            "|Alice|   Finance|  3800|\n",
            "|  Bob|        IT|  4500|\n",
            "+-----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter: employees with salary > 3500\n",
        "df_filtered = df.filter(df.Salary > 3500)\n",
        "df_filtered.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2qJQet_xtL2",
        "outputId": "db0a44ee-0834-4ba6-a744-6877e331d78b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+------+\n",
            "| Name|Department|Salary|\n",
            "+-----+----------+------+\n",
            "| Jane|   Finance|  4000|\n",
            "|Alice|   Finance|  3800|\n",
            "|  Bob|        IT|  4500|\n",
            "+-----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_grouped = df.groupBy(\"Department\").avg(\"salary\")\n",
        "df_grouped.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4u6sPCiyDdF",
        "outputId": "fd802356-95e1-44d6-a2ba-4e331fa39f7a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|Department|avg(salary)|\n",
            "+----------+-----------+\n",
            "|     Sales|     3250.0|\n",
            "|   Finance|     3900.0|\n",
            "|        IT|     4500.0|\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a new comumn: salary with new bones (10%)\n",
        "from pyspark.sql.functions import  col\n",
        "exp=col(\"Salary\") * 1.1\n",
        "df_with_bonus = df.withColumn(\"Salary_10%_Bonus\",exp)\n",
        "df_with_bonus.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qL8hFjFOzpEq",
        "outputId": "dce3c884-6352-4eb0-90e2-ff86b1654525"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+------+------------------+\n",
            "| Name|Department|Salary|  Salary_10%_Bonus|\n",
            "+-----+----------+------+------------------+\n",
            "| John|     Sales|  3000|3300.0000000000005|\n",
            "| Jane|   Finance|  4000|            4400.0|\n",
            "| Mike|     Sales|  3500|3850.0000000000005|\n",
            "|Alice|   Finance|  3800|            4180.0|\n",
            "|  Bob|        IT|  4500|            4950.0|\n",
            "+-----+----------+------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col,upper, lower, concat_ws,length,when\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnFuUJPV1I07",
        "outputId": "26bb23cb-11a5-4866-a190-ff25c8c2f7e3"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+------+\n",
            "| Name|Department|Salary|\n",
            "+-----+----------+------+\n",
            "| John|     Sales|  3000|\n",
            "| Jane|   Finance|  4000|\n",
            "| Mike|     Sales|  3500|\n",
            "|Alice|   Finance|  3800|\n",
            "|  Bob|        IT|  4500|\n",
            "+-----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_upper = df.withColumn(\"Name_upper\",upper(col(\"Name\")))\n",
        "df_lower = df.withColumn(\"Name_lower\", lower(col(\"Name\")))\n",
        "df_upper.show()\n",
        "df_lower.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbRaESgY2Uzk",
        "outputId": "d4d8aa80-c1e9-440d-fe5a-7174e73c2b41"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+------+----------+\n",
            "| Name|Department|Salary|Name_upper|\n",
            "+-----+----------+------+----------+\n",
            "| John|     Sales|  3000|      JOHN|\n",
            "| Jane|   Finance|  4000|      JANE|\n",
            "| Mike|     Sales|  3500|      MIKE|\n",
            "|Alice|   Finance|  3800|     ALICE|\n",
            "|  Bob|        IT|  4500|       BOB|\n",
            "+-----+----------+------+----------+\n",
            "\n",
            "+-----+----------+------+----------+\n",
            "| Name|Department|Salary|Name_lower|\n",
            "+-----+----------+------+----------+\n",
            "| John|     Sales|  3000|      john|\n",
            "| Jane|   Finance|  4000|      jane|\n",
            "| Mike|     Sales|  3500|      mike|\n",
            "|Alice|   Finance|  3800|     alice|\n",
            "|  Bob|        IT|  4500|       bob|\n",
            "+-----+----------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_concat = df.withColumn(\"Full_length_Name\",concat_ws(\" \",col(\"Name\"),col(\"Department\")))\n",
        "df_concat.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQeJZZeT3Q0S",
        "outputId": "f7276e27-dca8-4a71-b026-0198df27ec03"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+------+----------------+\n",
            "| Name|Department|Salary|Full_length_Name|\n",
            "+-----+----------+------+----------------+\n",
            "| John|     Sales|  3000|      John Sales|\n",
            "| Jane|   Finance|  4000|    Jane Finance|\n",
            "| Mike|     Sales|  3500|      Mike Sales|\n",
            "|Alice|   Finance|  3800|   Alice Finance|\n",
            "|  Bob|        IT|  4500|          Bob IT|\n",
            "+-----+----------+------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# String leangth of Names in New DF\n",
        "df_length = df.withColumn(\"Name_length\",length(col(\"Name\")))\n",
        "df_length.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Idva0z_3XOK",
        "outputId": "b429794e-7e7f-4abc-e6c2-485c9875d73e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+------+-----------+\n",
            "| Name|Department|Salary|Name_length|\n",
            "+-----+----------+------+-----------+\n",
            "| John|     Sales|  3000|          4|\n",
            "| Jane|   Finance|  4000|          4|\n",
            "| Mike|     Sales|  3500|          4|\n",
            "|Alice|   Finance|  3800|          5|\n",
            "|  Bob|        IT|  4500|          3|\n",
            "+-----+----------+------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g3SiP6aY33ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the column (Salary --> Base_Salary)\n",
        "df_renamed = df.withColumnRenamed(\"Salary\",\"Base_salary\")\n",
        "df_renamed.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eggHzJgk5Amy",
        "outputId": "eb6cc9c1-97f9-42a2-a151-a2bc16630a44"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+-----------+\n",
            "| Name|Department|Base_salary|\n",
            "+-----+----------+-----------+\n",
            "| John|     Sales|       3000|\n",
            "| Jane|   Finance|       4000|\n",
            "| Mike|     Sales|       3500|\n",
            "|Alice|   Finance|       3800|\n",
            "|  Bob|        IT|       4500|\n",
            "+-----+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WlVZodkHLKh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advance"
      ],
      "metadata": {
        "id": "G3HGEg7nN5CN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark =SparkSession.builder.appName(\"Basics\").getOrCreate()\n",
        "columns = [\"Name\",\"Department\",\"Salary\"]\n",
        "data = [\n",
        "    (\"John\", \"Sales\", 3000),\n",
        "    (\"Jane\", \"Finance\", 4000),\n",
        "    (\"Mike\", \"Sales\", 3500),\n",
        "    (\"Alice\", \"Finance\", 3800),\n",
        "    (\"Bob\", \"IT\", 4500)\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iH22Se56Jug",
        "outputId": "36dd02ce-c751-4d66-9395-89728fc9df8b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+------+\n",
            "| Name|Department|Salary|\n",
            "+-----+----------+------+\n",
            "| John|     Sales|  3000|\n",
            "| Jane|   Finance|  4000|\n",
            "| Mike|     Sales|  3500|\n",
            "|Alice|   Finance|  3800|\n",
            "|  Bob|        IT|  4500|\n",
            "+-----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"Department\").agg({\"Salary\":\"avg\"}).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFvOY1PIOPHI",
        "outputId": "60470295-9716-47ce-ee2b-e11d695cb67c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|Department|avg(Salary)|\n",
            "+----------+-----------+\n",
            "|     Sales|     3250.0|\n",
            "|   Finance|     3900.0|\n",
            "|        IT|     4500.0|\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"Department\").avg(\"Salary\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAPqHIMwPLCn",
        "outputId": "39d422f5-1a1f-4258-9345-a6bff005af58"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|Department|avg(Salary)|\n",
            "+----------+-----------+\n",
            "|     Sales|     3250.0|\n",
            "|   Finance|     3900.0|\n",
            "|        IT|     4500.0|\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"Department\").agg({\"Salary\":\"avg\", \"Salary\":\"min\"}).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9DCIGdZPla6",
        "outputId": "084faa4d-ee13-46f6-bdce-61d9572fe63f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|Department|min(Salary)|\n",
            "+----------+-----------+\n",
            "|     Sales|       3000|\n",
            "|   Finance|       3800|\n",
            "|        IT|       4500|\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "df.groupBy(\"Department\") \\\n",
        "   .agg(F.avg(\"Salary\").alias(\"Average_Salary\"),\n",
        "        F.max(\"Salary\").alias(\"Max_Salary\"),\n",
        "        F.min(\"Salary\").alias(\"Min_Salary\")) \\\n",
        "   .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wag3ZpT7P-qW",
        "outputId": "b0f8aaab-351c-454f-d37a-1346879867a5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------+----------+----------+\n",
            "|Department|Average_Salary|Max_Salary|Min_Salary|\n",
            "+----------+--------------+----------+----------+\n",
            "|     Sales|        3250.0|      3500|      3000|\n",
            "|   Finance|        3900.0|      4000|      3800|\n",
            "|        IT|        4500.0|      4500|      4500|\n",
            "+----------+--------------+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create another DataFrame for department info\n",
        "dept_data = [\n",
        "    (\"Sales\", \"Building A\"),\n",
        "    (\"Finance\", \"Building B\"),\n",
        "    (\"IT\", \"Building C\")\n",
        "]\n",
        "dept_columns = [\"Department\", \"Location\"]\n",
        "\n",
        "dept_df=spark.createDataFrame(dept_data, dept_columns)\n",
        "dept_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-ax8hAJR3NS",
        "outputId": "6de2ceb9-fffb-45bc-c5bb-7adb0676a213"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+\n",
            "|Department|  Location|\n",
            "+----------+----------+\n",
            "|     Sales|Building A|\n",
            "|   Finance|Building B|\n",
            "|        IT|Building C|\n",
            "+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create another DataFrame for department info\n",
        "dept_data = [\n",
        "    (\"Sales\", \"Building A\"),\n",
        "    (\"Finance\", \"Building B\"),\n",
        "    (\"IT\", \"Building C\")\n",
        "]\n",
        "dept_columns = [\"Department\", \"Location\"]\n",
        "\n",
        "dept_df=spark.createDataFrame(dept_data, dept_columns)\n",
        "dept_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGMD86-cTwdS",
        "outputId": "cea8dd98-8a3d-453c-ab81-d088ff1ba314"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+\n",
            "|Department|  Location|\n",
            "+----------+----------+\n",
            "|     Sales|Building A|\n",
            "|   Finance|Building B|\n",
            "|        IT|Building C|\n",
            "+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dept_df = spark.createDataFrame(dept_data, dept_columns)\n",
        "\n",
        "joined_df = df.join(dept_df, on=\"Department\", how=\"inner\")\n",
        "joined_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKa960E3TGTL",
        "outputId": "a1ea3c2a-ad26-4d12-f2c2-eae9b945cee8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+------+----------+\n",
            "|Department| Name|Salary|  Location|\n",
            "+----------+-----+------+----------+\n",
            "|   Finance| Jane|  4000|Building B|\n",
            "|   Finance|Alice|  3800|Building B|\n",
            "|        IT|  Bob|  4500|Building C|\n",
            "|     Sales| John|  3000|Building A|\n",
            "|     Sales| Mike|  3500|Building A|\n",
            "+----------+-----+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dept_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXLBxOjjT8ti",
        "outputId": "af0261dc-dc6a-4cb9-8795-b39a4e0cc699"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+\n",
            "|Department|  Location|\n",
            "+----------+----------+\n",
            "|     Sales|Building A|\n",
            "|   Finance|Building B|\n",
            "|        IT|Building C|\n",
            "+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Employee DataFrame\n",
        "emp_data = [\n",
        "    (1, \"John\", \"Sales\", 3000),\n",
        "    (2, \"Jane\", \"Finance\", 4000),\n",
        "    (3, \"Mike\", \"Sales\", 3500),\n",
        "    (4, \"Alice\", \"HR\", 3800),\n",
        "    (5, \"Bob\", \"IT\", 4500),\n",
        "    (6, \"Sam\", \"Support\", 3200)\n",
        "]\n",
        "emp_cols = [\"EmpID\", \"Name\", \"Department\", \"Salary\"]\n",
        "emp_df = spark.createDataFrame(emp_data, emp_cols)\n",
        "\n",
        "# Department DataFrame\n",
        "dept_data = [\n",
        "    (\"Sales\", \"Building A\"),\n",
        "    (\"Finance\", \"Building B\"),\n",
        "    (\"IT\", \"Building C\"),\n",
        "    (\"Admin\", \"Building D\")\n",
        "]\n",
        "dept_cols = [\"Department\", \"Location\"]\n",
        "dept_df = spark.createDataFrame(dept_data, dept_cols)\n",
        "\n",
        "# Display both\n",
        "emp_df.show()\n",
        "dept_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KT6v2E4UGzU",
        "outputId": "95671345-a97b-460f-b7c2-ea29cec0c943"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+----------+------+\n",
            "|EmpID| Name|Department|Salary|\n",
            "+-----+-----+----------+------+\n",
            "|    1| John|     Sales|  3000|\n",
            "|    2| Jane|   Finance|  4000|\n",
            "|    3| Mike|     Sales|  3500|\n",
            "|    4|Alice|        HR|  3800|\n",
            "|    5|  Bob|        IT|  4500|\n",
            "|    6|  Sam|   Support|  3200|\n",
            "+-----+-----+----------+------+\n",
            "\n",
            "+----------+----------+\n",
            "|Department|  Location|\n",
            "+----------+----------+\n",
            "|     Sales|Building A|\n",
            "|   Finance|Building B|\n",
            "|        IT|Building C|\n",
            "|     Admin|Building D|\n",
            "+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emp_df.join(dept_df, on=\"Department\", how=\"inner\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMURZs9oVSA-",
        "outputId": "64f734a0-285f-4775-9152-a0da3a7c9982"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+----+------+----------+\n",
            "|Department|EmpID|Name|Salary|  Location|\n",
            "+----------+-----+----+------+----------+\n",
            "|   Finance|    2|Jane|  4000|Building B|\n",
            "|        IT|    5| Bob|  4500|Building C|\n",
            "|     Sales|    1|John|  3000|Building A|\n",
            "|     Sales|    3|Mike|  3500|Building A|\n",
            "+----------+-----+----+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# left join\n",
        "emp_df.join(dept_df, on=\"Department\", how=\"left\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyWA9eNGVfUk",
        "outputId": "f2a75c4a-aa58-49cb-a104-667f8c2a12bb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----+------+----------+\n",
            "|Department|EmpID| Name|Salary|  Location|\n",
            "+----------+-----+-----+------+----------+\n",
            "|     Sales|    1| John|  3000|Building A|\n",
            "|     Sales|    3| Mike|  3500|Building A|\n",
            "|   Finance|    2| Jane|  4000|Building B|\n",
            "|        HR|    4|Alice|  3800|      NULL|\n",
            "|        IT|    5|  Bob|  4500|Building C|\n",
            "|   Support|    6|  Sam|  3200|      NULL|\n",
            "+----------+-----+-----+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emp_df.join(dept_df, on=\"Department\", how=\"right\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd5tYkmkVrs6",
        "outputId": "63678785-9822-4d6a-966b-f0700a486ec0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+----+------+----------+\n",
            "|Department|EmpID|Name|Salary|  Location|\n",
            "+----------+-----+----+------+----------+\n",
            "|     Sales|    3|Mike|  3500|Building A|\n",
            "|     Sales|    1|John|  3000|Building A|\n",
            "|   Finance|    2|Jane|  4000|Building B|\n",
            "|     Admin| NULL|NULL|  NULL|Building D|\n",
            "|        IT|    5| Bob|  4500|Building C|\n",
            "+----------+-----+----+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emp_df.join(dept_df, on=\"Department\", how=\"full\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sd6lHzGIVzd-",
        "outputId": "95409f65-ca23-490d-c0fa-508a1b4f78de"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----+------+----------+\n",
            "|Department|EmpID| Name|Salary|  Location|\n",
            "+----------+-----+-----+------+----------+\n",
            "|     Admin| NULL| NULL|  NULL|Building D|\n",
            "|   Finance|    2| Jane|  4000|Building B|\n",
            "|        HR|    4|Alice|  3800|      NULL|\n",
            "|        IT|    5|  Bob|  4500|Building C|\n",
            "|     Sales|    1| John|  3000|Building A|\n",
            "|     Sales|    3| Mike|  3500|Building A|\n",
            "|   Support|    6|  Sam|  3200|      NULL|\n",
            "+----------+-----+-----+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SALES.csv"
      ],
      "metadata": {
        "id": "pJHJcDwioVYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assignment\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType, StringType, TimestampType\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "spark = SparkSession.builder.appName(\"SalesData\").getOrCreate()\n",
        "\n",
        "# Define schema\n",
        "schema = StructType([\n",
        "    StructField(\"sale_id\", IntegerType(), True),\n",
        "    StructField(\"product_id\", IntegerType(), True),\n",
        "    StructField(\"customer_id\", IntegerType(), True),\n",
        "    StructField(\"sale_date\", StringType(), True),  # or TimestampType()\n",
        "    StructField(\"quantity\", IntegerType(), True),\n",
        "    StructField(\"price\", DoubleType(), True)\n",
        "])\n",
        "\n",
        "# Create data\n",
        "data = [\n",
        "    (1001, 101, 501, \"2025-07-10 08:23:00\", 3, 25.5),\n",
        "    (1002, 102, 502, \"2025-07-11 09:45:00\", 2, 15.0),\n",
        "    (1003, 103, 503, \"2025-07-12 10:15:00\", 1, 30.0),\n",
        "    (1004, 101, 504, \"2025-07-13 12:20:00\", 5, 25.5),\n",
        "    (1005, 105, 505, \"2025-07-14 14:35:00\", 10, 45.0),\n",
        "    (1006, 102, 506, \"2025-07-15 16:00:00\", 4, 15.0),\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(data, schema=schema)\n",
        "df = df.withColumn(\"sale_date\", F.to_timestamp(\"sale_date\"))\n",
        "df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fa1ZzS7cWIpR",
        "outputId": "8f9f43b5-3621-4e07-8cd1-fb66638c4a07"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-----------+-------------------+--------+-----+\n",
            "|sale_id|product_id|customer_id|          sale_date|quantity|price|\n",
            "+-------+----------+-----------+-------------------+--------+-----+\n",
            "|   1001|       101|        501|2025-07-10 08:23:00|       3| 25.5|\n",
            "|   1002|       102|        502|2025-07-11 09:45:00|       2| 15.0|\n",
            "|   1003|       103|        503|2025-07-12 10:15:00|       1| 30.0|\n",
            "|   1004|       101|        504|2025-07-13 12:20:00|       5| 25.5|\n",
            "|   1005|       105|        505|2025-07-14 14:35:00|      10| 45.0|\n",
            "|   1006|       102|        506|2025-07-15 16:00:00|       4| 15.0|\n",
            "+-------+----------+-----------+-------------------+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
        "\n",
        "# Define schema for products\n",
        "product_schema = StructType([\n",
        "    StructField(\"product_id\", IntegerType(), True),\n",
        "    StructField(\"product_name\", StringType(), True),\n",
        "    StructField(\"category\", StringType(), True),\n",
        "])\n",
        "\n",
        "# Create product data\n",
        "products_data = [\n",
        "    (101, \"Widget A\", \"Gadgets\"),\n",
        "    (102, \"Widget B\", \"Gadgets\"),\n",
        "    (103, \"Widget C\", \"Electronics\"),\n",
        "    (104, \"Widget D\", \"Electronics\"),\n",
        "    (105, \"Widget E\", \"Home & Living\"),\n",
        "]\n",
        "\n",
        "# Create DataFrame\n",
        "df_products = spark.createDataFrame(products_data, schema=product_schema)\n",
        "df_products.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2UKYhzqZtn0",
        "outputId": "4169b7f1-95da-43d6-9dca-ccd8de97833d"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+-------------+\n",
            "|product_id|product_name|     category|\n",
            "+----------+------------+-------------+\n",
            "|       101|    Widget A|      Gadgets|\n",
            "|       102|    Widget B|      Gadgets|\n",
            "|       103|    Widget C|  Electronics|\n",
            "|       104|    Widget D|  Electronics|\n",
            "|       105|    Widget E|Home & Living|\n",
            "+----------+------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, TimestampType\n",
        "\n",
        "# Define schema\n",
        "customer_schema = StructType([\n",
        "    StructField(\"customer_id\", IntegerType(), True),\n",
        "    StructField(\"customer_name\", StringType(), True),\n",
        "    StructField(\"email\", StringType(), True),\n",
        "    StructField(\"join_date\", StringType(), True),  # or use TimestampType\n",
        "])\n",
        "\n",
        "# Create data\n",
        "customer_data = [\n",
        "    (501, \"Alice\", \"alice@example.com\", \"2025-05-20 10:10:00\"),\n",
        "    (502, \"Bob\", \"bob@example.com\", \"2025-06-15 14:00:00\"),\n",
        "    (503, \"Charlie\", \"charlie@example.com\", \"2025-04-05 09:50:00\"),\n",
        "    (504, \"David\", \"david@example.com\", \"2025-07-01 12:25:00\"),\n",
        "    (505, \"Emma\", \"emma@example.com\", \"2025-07-10 15:30:00\"),\n",
        "    (506, \"Frank\", \"frank@example.com\", \"2025-03-23 17:00:00\"),\n",
        "]\n",
        "\n",
        "# Create DataFrame\n",
        "df_customers = spark.createDataFrame(customer_data, schema=customer_schema) \\\n",
        "    .withColumn(\"join_date\", F.to_timestamp(\"join_date\"))\n",
        "\n",
        "df_customers.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dE4dVCTBaJ45",
        "outputId": "1f1a501e-073b-48df-f1ab-3b3344baeb4b"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+-------------------+-------------------+\n",
            "|customer_id|customer_name|              email|          join_date|\n",
            "+-----------+-------------+-------------------+-------------------+\n",
            "|        501|        Alice|  alice@example.com|2025-05-20 10:10:00|\n",
            "|        502|          Bob|    bob@example.com|2025-06-15 14:00:00|\n",
            "|        503|      Charlie|charlie@example.com|2025-04-05 09:50:00|\n",
            "|        504|        David|  david@example.com|2025-07-01 12:25:00|\n",
            "|        505|         Emma|   emma@example.com|2025-07-10 15:30:00|\n",
            "|        506|        Frank|  frank@example.com|2025-03-23 17:00:00|\n",
            "+-----------+-------------+-------------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df contains sales data with: product_id, quantity, price\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "df.withColumn(\"revenue\", F.col(\"quantity\") * F.col(\"price\")) \\\n",
        "  .groupBy(\"product_id\") \\\n",
        "  .agg(F.sum(\"revenue\").alias(\"total_revenue\")) \\\n",
        "  .orderBy(F.desc(\"total_revenue\")) \\\n",
        "  .show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCQFKQG-ao5T",
        "outputId": "62ec255e-0f63-4888-ac6d-19be2c447e1e"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------+\n",
            "|product_id|total_revenue|\n",
            "+----------+-------------+\n",
            "|       105|        450.0|\n",
            "|       101|        204.0|\n",
            "|       102|         90.0|\n",
            "|       103|         30.0|\n",
            "+----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Option 1: Use customer_id only\n",
        "df.groupBy(\"customer_id\") \\\n",
        "  .agg(F.sum(\"quantity\").alias(\"total_quantity\")) \\\n",
        "  .orderBy(F.desc(\"total_quantity\")) \\\n",
        "  .show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pn2Qay-YbHdk",
        "outputId": "5f542244-7f44-41e3-ee92-2a2e058c5c7b"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------+\n",
            "|customer_id|total_quantity|\n",
            "+-----------+--------------+\n",
            "|        505|            10|\n",
            "|        504|             5|\n",
            "|        506|             4|\n",
            "|        501|             3|\n",
            "|        502|             2|\n",
            "|        503|             1|\n",
            "+-----------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Join sales with products\n",
        "df_joined = df.join(df_products, on=\"product_id\", how=\"inner\")\n",
        "\n",
        "# Then join with customers\n",
        "df_full = df_joined.join(df_customers, on=\"customer_id\", how=\"inner\")\n"
      ],
      "metadata": {
        "id": "_Wvk9iZLcXny"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "df_full.groupBy(\"customer_name\") \\\n",
        "       .agg(F.sum(\"quantity\").alias(\"total_quantity\")) \\\n",
        "       .orderBy(F.desc(\"total_quantity\")) \\\n",
        "       .show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SYG2RI0cgbV",
        "outputId": "7abae3dc-0981-4723-ff7f-1cdc9fcd2fe4"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+--------------+\n",
            "|customer_name|total_quantity|\n",
            "+-------------+--------------+\n",
            "|         Emma|            10|\n",
            "|        David|             5|\n",
            "|        Frank|             4|\n",
            "|        Alice|             3|\n",
            "|          Bob|             2|\n",
            "|      Charlie|             1|\n",
            "+-------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Make sure df_full includes: customer_id, customer_name, quantity, price\n",
        "df_full.withColumn(\"revenue\", F.col(\"quantity\") * F.col(\"price\")) \\\n",
        "       .groupBy(\"customer_name\") \\\n",
        "       .agg(F.avg(\"revenue\").alias(\"average_revenue\")) \\\n",
        "       .orderBy(F.desc(\"average_revenue\")) \\\n",
        "       .show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hvkrKsrb2xb",
        "outputId": "5a878710-4584-4bb4-a76b-8a505a3ddf26"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+---------------+\n",
            "|customer_name|average_revenue|\n",
            "+-------------+---------------+\n",
            "|         Emma|          450.0|\n",
            "|        David|          127.5|\n",
            "|        Alice|           76.5|\n",
            "|        Frank|           60.0|\n",
            "|      Charlie|           30.0|\n",
            "|          Bob|           30.0|\n",
            "+-------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Step 1: Add a 'revenue' column\n",
        "df_with_revenue = df.withColumn(\"revenue\", F.col(\"quantity\") * F.col(\"price\"))\n",
        "\n",
        "# Step 2: Extract year and month from 'sale_date'\n",
        "df_monthly = df_with_revenue.withColumn(\"year_month\", F.date_format(\"sale_date\", \"yyyy-MM\"))\n",
        "\n",
        "# Step 3: Group by 'year_month' and sum revenue\n",
        "df_monthly.groupBy(\"year_month\") \\\n",
        "    .agg(F.round(F.sum(\"revenue\"), 2).alias(\"total_revenue\")) \\\n",
        "    .orderBy(\"year_month\") \\\n",
        "    .show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOvUu8becu7H",
        "outputId": "cb545e6c-b979-4837-c8aa-71c82e23aab6"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------+\n",
            "|year_month|total_revenue|\n",
            "+----------+-------------+\n",
            "|   2025-07|        774.0|\n",
            "+----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "df_sales_by_category = df.join(df_products, on=\"product_id\", how=\"inner\") \\\n",
        "    .groupBy(\"category\") \\\n",
        "    .agg(F.count(\"*\").alias(\"total_sales\")) \\\n",
        "    .orderBy(F.desc(\"total_sales\"))\n",
        "\n",
        "df_sales_by_category.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUgfpq_rdPB5",
        "outputId": "903ceefd-86b7-4f0a-ed8b-70eaa602c2b9"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----------+\n",
            "|     category|total_sales|\n",
            "+-------------+-----------+\n",
            "|      Gadgets|          4|\n",
            "|  Electronics|          1|\n",
            "|Home & Living|          1|\n",
            "+-------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Step 1: Calculate revenue per row\n",
        "df_revenue = df.withColumn(\"revenue\", F.col(\"quantity\") * F.col(\"price\"))\n",
        "\n",
        "# Step 2: Join with products to get product names\n",
        "df_with_names = df_revenue.join(df_products, on=\"product_id\", how=\"inner\")\n",
        "\n",
        "# Step 3: Group by product and sum revenue\n",
        "df_top_products = df_with_names.groupBy(\"product_name\") \\\n",
        "    .agg(F.round(F.sum(\"revenue\"), 2).alias(\"total_revenue\")) \\\n",
        "    .orderBy(F.desc(\"total_revenue\")) \\\n",
        "    .limit(3)\n",
        "\n",
        "# Step 4: Show result\n",
        "df_top_products.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2J-vJURdY4H",
        "outputId": "42c16366-80c1-4f07-f420-f81e9df33fbd"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------------+\n",
            "|product_name|total_revenue|\n",
            "+------------+-------------+\n",
            "|    Widget E|        450.0|\n",
            "|    Widget A|        204.0|\n",
            "|    Widget B|         90.0|\n",
            "+------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# joins\n",
        "\n",
        "# Join sales_data with product_data on product_id\n",
        "df_sales_with_products = df.join(df_products, on=\"product_id\", how=\"inner\")\n",
        "\n",
        "# Select the relevant columns\n",
        "df_sales_with_products.select(\n",
        "    \"sale_id\",\n",
        "    \"product_id\",\n",
        "    \"product_name\",\n",
        "    \"category\",\n",
        "    \"customer_id\",\n",
        "    \"sale_date\",\n",
        "    \"quantity\",\n",
        "    \"price\"\n",
        ").show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJLuvvA0dzJI",
        "outputId": "a4e24265-82f9-4ad3-cbde-30087d27bf3b"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+------------+-------------+-----------+-------------------+--------+-----+\n",
            "|sale_id|product_id|product_name|category     |customer_id|sale_date          |quantity|price|\n",
            "+-------+----------+------------+-------------+-----------+-------------------+--------+-----+\n",
            "|1001   |101       |Widget A    |Gadgets      |501        |2025-07-10 08:23:00|3       |25.5 |\n",
            "|1004   |101       |Widget A    |Gadgets      |504        |2025-07-13 12:20:00|5       |25.5 |\n",
            "|1002   |102       |Widget B    |Gadgets      |502        |2025-07-11 09:45:00|2       |15.0 |\n",
            "|1006   |102       |Widget B    |Gadgets      |506        |2025-07-15 16:00:00|4       |15.0 |\n",
            "|1003   |103       |Widget C    |Electronics  |503        |2025-07-12 10:15:00|1       |30.0 |\n",
            "|1005   |105       |Widget E    |Home & Living|505        |2025-07-14 14:35:00|10      |45.0 |\n",
            "+-------+----------+------------+-------------+-----------+-------------------+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Join sales with customer data on customer_id\n",
        "df_sales_with_customers = df.join(df_customers, on=\"customer_id\", how=\"inner\")\n",
        "\n",
        "# Select columns for detailed sales info with customer name and email\n",
        "df_sales_with_customers.select(\n",
        "    \"sale_id\",\n",
        "    \"customer_id\",\n",
        "    \"customer_name\",\n",
        "    \"email\",\n",
        "    \"sale_date\",\n",
        "    \"product_id\",\n",
        "    \"quantity\",\n",
        "    \"price\"\n",
        ").show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvZ70a8OlJo9",
        "outputId": "ee3918c1-006c-42ee-bdd3-b36db499e475"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+-------------+-------------------+-------------------+----------+--------+-----+\n",
            "|sale_id|customer_id|customer_name|email              |sale_date          |product_id|quantity|price|\n",
            "+-------+-----------+-------------+-------------------+-------------------+----------+--------+-----+\n",
            "|1001   |501        |Alice        |alice@example.com  |2025-07-10 08:23:00|101       |3       |25.5 |\n",
            "|1002   |502        |Bob          |bob@example.com    |2025-07-11 09:45:00|102       |2       |15.0 |\n",
            "|1003   |503        |Charlie      |charlie@example.com|2025-07-12 10:15:00|103       |1       |30.0 |\n",
            "|1004   |504        |David        |david@example.com  |2025-07-13 12:20:00|101       |5       |25.5 |\n",
            "|1005   |505        |Emma         |emma@example.com   |2025-07-14 14:35:00|105       |10      |45.0 |\n",
            "|1006   |506        |Frank        |frank@example.com  |2025-07-15 16:00:00|102       |4       |15.0 |\n",
            "+-------+-----------+-------------+-------------------+-------------------+----------+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Step 1: Join sales and product data\n",
        "df_sales_with_category = df.join(df_products, on=\"product_id\", how=\"inner\")\n",
        "\n",
        "# Step 2: Filter for category 'Gadgets'\n",
        "df_gadgets_sales = df_sales_with_category.filter(F.col(\"category\") == \"Gadgets\")\n",
        "\n",
        "# Step 3: Show selected fields\n",
        "df_gadgets_sales.select(\n",
        "    \"sale_id\", \"product_id\", \"product_name\", \"category\",\n",
        "    \"customer_id\", \"sale_date\", \"quantity\", \"price\"\n",
        ").show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ec9cypllXat",
        "outputId": "0465921b-4694-4fea-c366-38131e6750e9"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+------------+--------+-----------+-------------------+--------+-----+\n",
            "|sale_id|product_id|product_name|category|customer_id|sale_date          |quantity|price|\n",
            "+-------+----------+------------+--------+-----------+-------------------+--------+-----+\n",
            "|1001   |101       |Widget A    |Gadgets |501        |2025-07-10 08:23:00|3       |25.5 |\n",
            "|1004   |101       |Widget A    |Gadgets |504        |2025-07-13 12:20:00|5       |25.5 |\n",
            "|1002   |102       |Widget B    |Gadgets |502        |2025-07-11 09:45:00|2       |15.0 |\n",
            "|1006   |102       |Widget B    |Gadgets |506        |2025-07-15 16:00:00|4       |15.0 |\n",
            "+-------+----------+------------+--------+-----------+-------------------+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform LEFT JOIN between sales and products\n",
        "df_sales_left_join = df.join(df_products, on=\"product_id\", how=\"left\")\n",
        "\n",
        "# Show key fields, including nulls if product info is missing\n",
        "df_sales_left_join.select(\n",
        "    \"sale_id\",\n",
        "    \"product_id\",\n",
        "    \"product_name\",\n",
        "    \"category\",\n",
        "    \"customer_id\",\n",
        "    \"sale_date\",\n",
        "    \"quantity\",\n",
        "    \"price\"\n",
        ").show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96aU-KIflrrr",
        "outputId": "490bd3f2-c530-4a5e-acd2-943f503d6e99"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+------------+-------------+-----------+-------------------+--------+-----+\n",
            "|sale_id|product_id|product_name|category     |customer_id|sale_date          |quantity|price|\n",
            "+-------+----------+------------+-------------+-----------+-------------------+--------+-----+\n",
            "|1001   |101       |Widget A    |Gadgets      |501        |2025-07-10 08:23:00|3       |25.5 |\n",
            "|1003   |103       |Widget C    |Electronics  |503        |2025-07-12 10:15:00|1       |30.0 |\n",
            "|1002   |102       |Widget B    |Gadgets      |502        |2025-07-11 09:45:00|2       |15.0 |\n",
            "|1004   |101       |Widget A    |Gadgets      |504        |2025-07-13 12:20:00|5       |25.5 |\n",
            "|1006   |102       |Widget B    |Gadgets      |506        |2025-07-15 16:00:00|4       |15.0 |\n",
            "|1005   |105       |Widget E    |Home & Living|505        |2025-07-14 14:35:00|10      |45.0 |\n",
            "+-------+----------+------------+-------------+-----------+-------------------+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Alias the sales data for self-join\n",
        "sales1 = df.alias(\"s1\")\n",
        "sales2 = df.alias(\"s2\")\n",
        "\n",
        "# Perform the self-join on product_id where sale_dates are different\n",
        "df_self_joined = sales1.join(\n",
        "    sales2,\n",
        "    (col(\"s1.product_id\") == col(\"s2.product_id\")) &\n",
        "    (col(\"s1.sale_date\") < col(\"s2.sale_date\")),  # avoid same and duplicate pairs\n",
        "    how=\"inner\"\n",
        ")\n",
        "\n",
        "# Select relevant comparison fields\n",
        "df_self_joined.select(\n",
        "    col(\"s1.product_id\"),\n",
        "    col(\"s1.sale_id\").alias(\"sale_id_1\"),\n",
        "    col(\"s1.sale_date\").alias(\"sale_date_1\"),\n",
        "    col(\"s1.quantity\").alias(\"quantity_1\"),\n",
        "    col(\"s2.sale_id\").alias(\"sale_id_2\"),\n",
        "    col(\"s2.sale_date\").alias(\"sale_date_2\"),\n",
        "    col(\"s2.quantity\").alias(\"quantity_2\")\n",
        ").orderBy(\"product_id\", \"sale_date_1\").show(truncate=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tin10qcRl0jW",
        "outputId": "b8234231-2b97-460a-d581-03f3e0f9953d"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+-------------------+----------+---------+-------------------+----------+\n",
            "|product_id|sale_id_1|sale_date_1        |quantity_1|sale_id_2|sale_date_2        |quantity_2|\n",
            "+----------+---------+-------------------+----------+---------+-------------------+----------+\n",
            "|101       |1001     |2025-07-10 08:23:00|3         |1004     |2025-07-13 12:20:00|5         |\n",
            "|102       |1002     |2025-07-11 09:45:00|2         |1006     |2025-07-15 16:00:00|4         |\n",
            "+----------+---------+-------------------+----------+---------+-------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform full outer join on product_id\n",
        "df_full_outer = df.join(df_products, on=\"product_id\", how=\"outer\")\n",
        "\n",
        "# Select relevant fields\n",
        "df_full_outer.select(\n",
        "    \"product_id\",\n",
        "    \"product_name\",\n",
        "    \"category\",\n",
        "    \"sale_id\",\n",
        "    \"customer_id\",\n",
        "    \"sale_date\",\n",
        "    \"quantity\",\n",
        "    \"price\"\n",
        ").orderBy(\"product_id\").show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thZtbCgMmXY2",
        "outputId": "e41855db-ba36-41db-815e-4512fc26b89b"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+-------------+-------+-----------+-------------------+--------+-----+\n",
            "|product_id|product_name|category     |sale_id|customer_id|sale_date          |quantity|price|\n",
            "+----------+------------+-------------+-------+-----------+-------------------+--------+-----+\n",
            "|101       |Widget A    |Gadgets      |1001   |501        |2025-07-10 08:23:00|3       |25.5 |\n",
            "|101       |Widget A    |Gadgets      |1004   |504        |2025-07-13 12:20:00|5       |25.5 |\n",
            "|102       |Widget B    |Gadgets      |1002   |502        |2025-07-11 09:45:00|2       |15.0 |\n",
            "|102       |Widget B    |Gadgets      |1006   |506        |2025-07-15 16:00:00|4       |15.0 |\n",
            "|103       |Widget C    |Electronics  |1003   |503        |2025-07-12 10:15:00|1       |30.0 |\n",
            "|104       |Widget D    |Electronics  |NULL   |NULL       |NULL               |NULL    |NULL |\n",
            "|105       |Widget E    |Home & Living|1005   |505        |2025-07-14 14:35:00|10      |45.0 |\n",
            "+----------+------------+-------------+-------+-----------+-------------------+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Step 1: Join sales with customers\n",
        "df_sales_customers = df.join(df_customers, on=\"customer_id\", how=\"inner\")\n",
        "\n",
        "# Step 2: Join the above result with products\n",
        "df_complete_sales = df_sales_customers.join(df_products, on=\"product_id\", how=\"inner\")\n",
        "\n",
        "# Step 3: Select and display relevant columns\n",
        "df_complete_sales.select(\n",
        "    \"sale_id\",\n",
        "    \"sale_date\",\n",
        "    \"product_id\",\n",
        "    \"product_name\",\n",
        "    \"category\",\n",
        "    \"customer_id\",\n",
        "    \"customer_name\",\n",
        "    \"email\",\n",
        "    \"quantity\",\n",
        "    \"price\"\n",
        ").orderBy(\"sale_date\").show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPFVpO3LmfPH",
        "outputId": "3dfbeb7c-1293-41b5-9a62-6f79153dd7c2"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------------+----------+------------+-------------+-----------+-------------+-------------------+--------+-----+\n",
            "|sale_id|sale_date          |product_id|product_name|category     |customer_id|customer_name|email              |quantity|price|\n",
            "+-------+-------------------+----------+------------+-------------+-----------+-------------+-------------------+--------+-----+\n",
            "|1001   |2025-07-10 08:23:00|101       |Widget A    |Gadgets      |501        |Alice        |alice@example.com  |3       |25.5 |\n",
            "|1002   |2025-07-11 09:45:00|102       |Widget B    |Gadgets      |502        |Bob          |bob@example.com    |2       |15.0 |\n",
            "|1003   |2025-07-12 10:15:00|103       |Widget C    |Electronics  |503        |Charlie      |charlie@example.com|1       |30.0 |\n",
            "|1004   |2025-07-13 12:20:00|101       |Widget A    |Gadgets      |504        |David        |david@example.com  |5       |25.5 |\n",
            "|1005   |2025-07-14 14:35:00|105       |Widget E    |Home & Living|505        |Emma         |emma@example.com   |10      |45.0 |\n",
            "|1006   |2025-07-15 16:00:00|102       |Widget B    |Gadgets      |506        |Frank        |frank@example.com  |4       |15.0 |\n",
            "+-------+-------------------+----------+------------+-------------+-----------+-------------+-------------------+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Additional Transformations:\n",
        "\n",
        "from pyspark.sql.functions import col, to_timestamp\n",
        "\n",
        "# Ensure sale_date is in timestamp format (if it's a string)\n",
        "df_filtered = df.withColumn(\"sale_date\", to_timestamp(\"sale_date\"))\n",
        "\n",
        "# Filter rows between July 10 and July 15, 2025 (inclusive)\n",
        "df_sales_range = df_filtered.filter(\n",
        "    col(\"sale_date\").between(\"2025-07-10\", \"2025-07-15\")\n",
        ")\n",
        "\n",
        "# Show result\n",
        "df_sales_range.select(\"sale_id\", \"sale_date\", \"product_id\", \"quantity\", \"price\").show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKtViCPimwOJ",
        "outputId": "4a332c6f-4a8e-4160-a346-8e221e021c4b"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------------+----------+--------+-----+\n",
            "|sale_id|sale_date          |product_id|quantity|price|\n",
            "+-------+-------------------+----------+--------+-----+\n",
            "|1001   |2025-07-10 08:23:00|101       |3       |25.5 |\n",
            "|1002   |2025-07-11 09:45:00|102       |2       |15.0 |\n",
            "|1003   |2025-07-12 10:15:00|103       |1       |30.0 |\n",
            "|1004   |2025-07-13 12:20:00|101       |5       |25.5 |\n",
            "|1005   |2025-07-14 14:35:00|105       |10      |45.0 |\n",
            "+-------+-------------------+----------+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Step 1: Calculate revenue per transaction\n",
        "df_with_revenue = df.withColumn(\"revenue\", F.col(\"quantity\") * F.col(\"price\"))\n",
        "\n",
        "# Step 2: Join with customer data to get names\n",
        "df_with_customers = df_with_revenue.join(df_customers, on=\"customer_id\", how=\"inner\")\n",
        "\n",
        "# Step 3: Aggregate total revenue per customer\n",
        "df_customer_spending = df_with_customers.groupBy(\"customer_id\", \"customer_name\") \\\n",
        "    .agg(F.round(F.sum(\"revenue\"), 2).alias(\"total_spent\"))\n",
        "\n",
        "# Step 4: Order and limit to top 5\n",
        "df_top_5_customers = df_customer_spending.orderBy(F.desc(\"total_spent\")).limit(5)\n",
        "\n",
        "# Step 5: Show result\n",
        "df_top_5_customers.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aomJECxunKLt",
        "outputId": "f5603e2a-f0cf-4cba-a27d-657c008a2fd8"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+-----------+\n",
            "|customer_id|customer_name|total_spent|\n",
            "+-----------+-------------+-----------+\n",
            "|        505|         Emma|      450.0|\n",
            "|        504|        David|      127.5|\n",
            "|        501|        Alice|       76.5|\n",
            "|        506|        Frank|       60.0|\n",
            "|        502|          Bob|       30.0|\n",
            "+-----------+-------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "# Step 1: Compute revenue per transaction\n",
        "df_with_revenue = df.withColumn(\"revenue\", F.col(\"quantity\") * F.col(\"price\"))\n",
        "\n",
        "# Step 2: Join with customer data\n",
        "df_with_customers = df_with_revenue.join(df_customers, on=\"customer_id\", how=\"inner\")\n",
        "\n",
        "# Step 3: Total spending per customer\n",
        "df_total_spending = df_with_customers.groupBy(\"customer_id\", \"customer_name\") \\\n",
        "    .agg(F.round(F.sum(\"revenue\"), 2).alias(\"total_spent\"))\n",
        "\n",
        "# Step 4: Categorize into spending groups\n",
        "df_segmented = df_total_spending.withColumn(\n",
        "    \"spending_category\",\n",
        "    when(F.col(\"total_spent\") <= 100, \"Low Spender\")\n",
        "    .when((F.col(\"total_spent\") > 100) & (F.col(\"total_spent\") <= 300), \"Medium Spender\")\n",
        "    .otherwise(\"High Spender\")\n",
        ")\n",
        "\n",
        "# Step 5: Show the result\n",
        "df_segmented.orderBy(F.desc(\"total_spent\")).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0DV_Qu8nWzV",
        "outputId": "22c7ea9c-47b4-4e44-b5cf-8b35da9bc74b"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+-----------+-----------------+\n",
            "|customer_id|customer_name|total_spent|spending_category|\n",
            "+-----------+-------------+-----------+-----------------+\n",
            "|        505|         Emma|      450.0|     High Spender|\n",
            "|        504|        David|      127.5|   Medium Spender|\n",
            "|        501|        Alice|       76.5|      Low Spender|\n",
            "|        506|        Frank|       60.0|      Low Spender|\n",
            "|        502|          Bob|       30.0|      Low Spender|\n",
            "|        503|      Charlie|       30.0|      Low Spender|\n",
            "+-----------+-------------+-----------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import min, max, to_timestamp\n",
        "\n",
        "# Ensure sale_date is timestamp\n",
        "df_sales = df.withColumn(\"sale_date\", to_timestamp(\"sale_date\"))\n",
        "\n",
        "# Join with customer names (optional, for readability)\n",
        "df_with_customers = df_sales.join(df_customers, on=\"customer_id\", how=\"inner\")\n",
        "\n",
        "# Group by customer and find first and last purchase dates\n",
        "df_purchase_dates = df_with_customers.groupBy(\"customer_id\", \"customer_name\") \\\n",
        "    .agg(\n",
        "        min(\"sale_date\").alias(\"first_purchase\"),\n",
        "        max(\"sale_date\").alias(\"last_purchase\")\n",
        "    ) \\\n",
        "    .orderBy(\"customer_id\")\n",
        "\n",
        "# Show result\n",
        "df_purchase_dates.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzN8WuuwnZKc",
        "outputId": "4fdd05e7-e8dd-49ab-dbb1-3c6ccd5be82b"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+-------------------+-------------------+\n",
            "|customer_id|customer_name|first_purchase     |last_purchase      |\n",
            "+-----------+-------------+-------------------+-------------------+\n",
            "|501        |Alice        |2025-07-10 08:23:00|2025-07-10 08:23:00|\n",
            "|502        |Bob          |2025-07-11 09:45:00|2025-07-11 09:45:00|\n",
            "|503        |Charlie      |2025-07-12 10:15:00|2025-07-12 10:15:00|\n",
            "|504        |David        |2025-07-13 12:20:00|2025-07-13 12:20:00|\n",
            "|505        |Emma         |2025-07-14 14:35:00|2025-07-14 14:35:00|\n",
            "|506        |Frank        |2025-07-15 16:00:00|2025-07-15 16:00:00|\n",
            "+-----------+-------------+-------------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import max, to_timestamp, current_date, datediff\n",
        "\n",
        "# Ensure sale_date is timestamp\n",
        "df_sales = df.withColumn(\"sale_date\", to_timestamp(\"sale_date\"))\n",
        "\n",
        "# Step 1: Get last purchase date per customer\n",
        "df_last_purchase = df_sales.groupBy(\"customer_id\") \\\n",
        "    .agg(max(\"sale_date\").alias(\"last_purchase\"))\n",
        "\n",
        "# Step 2: Join with customer info\n",
        "df_customer_last = df_last_purchase.join(df_customers, on=\"customer_id\", how=\"inner\")\n",
        "\n",
        "# Step 3: Filter customers where last purchase was more than 30 days ago\n",
        "df_inactive_customers = df_customer_last.filter(\n",
        "    datediff(current_date(), \"last_purchase\") > 30\n",
        ")\n",
        "\n",
        "# Step 4: Show result\n",
        "df_inactive_customers.select(\"customer_id\", \"customer_name\", \"email\", \"last_purchase\").show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bNuzSONnmTQ",
        "outputId": "b5fea272-e19b-4808-810f-8e25a7d23196"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+-----+-------------+\n",
            "|customer_id|customer_name|email|last_purchase|\n",
            "+-----------+-------------+-----+-------------+\n",
            "+-----------+-------------+-----+-------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}